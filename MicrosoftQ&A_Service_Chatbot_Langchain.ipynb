{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "416755961d8a4a79bd691cf60ae85c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d95ff992a038470dae5ea25e75a444bb",
              "IPY_MODEL_5dae32026672413e85ad0faf45a58660",
              "IPY_MODEL_6001697917dc48b99dc57ab518c41658"
            ],
            "layout": "IPY_MODEL_a4288aacbe864119abd4d8ff643f4335"
          }
        },
        "d95ff992a038470dae5ea25e75a444bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_359d1d433eac4a8d9209d3e662664acd",
            "placeholder": "​",
            "style": "IPY_MODEL_14da015ab8e449128d8e13647c25c010",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "5dae32026672413e85ad0faf45a58660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc58938c310e4a7081ed9056ed33cfac",
            "max": 141,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1d82b8fe87547bf976721f641cc0709",
            "value": 141
          }
        },
        "6001697917dc48b99dc57ab518c41658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b48af65e2824d398ee696d2bbe05551",
            "placeholder": "​",
            "style": "IPY_MODEL_9f230860c77442d7ad9b589ce5f79281",
            "value": " 141/141 [00:00&lt;00:00, 5.97kB/s]"
          }
        },
        "a4288aacbe864119abd4d8ff643f4335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "359d1d433eac4a8d9209d3e662664acd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14da015ab8e449128d8e13647c25c010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc58938c310e4a7081ed9056ed33cfac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1d82b8fe87547bf976721f641cc0709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b48af65e2824d398ee696d2bbe05551": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f230860c77442d7ad9b589ce5f79281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#installing necessary libraries\n",
        "!pip install langchain==0.0.228 --progress-bar off\n",
        "!pip install gradio_client\n",
        "!pip install gradio\n",
        "!pip install chromadb==0.3.26 --progress-bar off\n",
        "!pip install sentence-transformers==2.2.2 --progress-bar off\n",
        "!pip install auto-gptq==0.2.2 --progress-bar off\n",
        "!pip install einops==0.6.1 --progress-bar off\n",
        "!pip install unstructured==0.8.0 --progress-bar off\n",
        "!pip install transformers==4.30.2 --progress-bar off\n",
        "!pip install torch==2.0.1 --progress-bar off\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWO3aVSKmF5t",
        "outputId": "0ed5bf1e-ecf2-4fab-a309-ebff349bb7f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.0.228\n",
            "  Downloading langchain-0.0.228-py3-none-any.whl (1.3 MB)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.228) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.228) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.228) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.228) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.228)\n",
            "  Downloading dataclasses_json-0.5.13-py3-none-any.whl (26 kB)\n",
            "Collecting langchainplus-sdk<0.0.21,>=0.0.20 (from langchain==0.0.228)\n",
            "  Downloading langchainplus_sdk-0.0.20-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.228) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.228) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.228)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.228) (1.10.11)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.228) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.228) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.228) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.228) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.228) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.228) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.228) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.228) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.228)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.228)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain==0.0.228) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.228) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.228) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.228) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.228) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.228) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.228)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, langchainplus-sdk, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.13 langchain-0.0.228 langchainplus-sdk-0.0.20 marshmallow-3.20.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0\n",
            "Collecting gradio_client\n",
            "  Downloading gradio_client-0.2.10-py3-none-any.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio_client) (2023.6.0)\n",
            "Collecting httpx (from gradio_client)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.13.0 (from gradio_client)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio_client) (23.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio_client) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio_client) (4.7.1)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio_client)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio_client) (3.12.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio_client) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio_client) (6.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio_client) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio_client) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio_client) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio_client) (3.4)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio_client)\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio_client) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore<0.18.0,>=0.15.0->httpx->gradio_client)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio_client) (3.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio_client) (1.1.2)\n",
            "Installing collected packages: websockets, h11, huggingface-hub, httpcore, httpx, gradio_client\n",
            "Successfully installed gradio_client-0.2.10 h11-0.14.0 httpcore-0.17.3 httpx-0.24.1 huggingface-hub-0.16.4 websockets-11.0.3\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.38.0-py3-none-any.whl (19.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: aiohttp~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.8.4)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.100.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gradio-client>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.2.10)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.16.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.0.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio)\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.22.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (8.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.11)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.27.1)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.7.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.23.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.10->gradio) (2023.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio)\n",
            "  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl (39 kB)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl (38 kB)\n",
            "  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl (38 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl (37 kB)\n",
            "Collecting markdown-it-py[linkify]>=2.0.0 (from gradio)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.6)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (0.17.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.7.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio) (1.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=1bb8665ab9ef8faccdf9bae4be8c0ce78c5028368f061a4e736dcd004c075875\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, uvicorn, uc-micro-py, semantic-version, python-multipart, orjson, markdown-it-py, aiofiles, starlette, mdit-py-plugins, linkify-it-py, fastapi, gradio\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "Successfully installed aiofiles-23.1.0 fastapi-0.100.0 ffmpy-0.3.1 gradio-3.38.0 linkify-it-py-2.0.2 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 orjson-3.9.2 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 uc-micro-py-1.0.2 uvicorn-0.23.1\n",
            "Collecting chromadb==0.3.26\n",
            "  Downloading chromadb-0.3.26-py3-none-any.whl (123 kB)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.26) (1.5.3)\n",
            "Collecting requests>=2.28 (from chromadb==0.3.26)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.26) (1.10.11)\n",
            "Collecting hnswlib>=0.7 (from chromadb==0.3.26)\n",
            "  Downloading hnswlib-0.7.0.tar.gz (33 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting clickhouse-connect>=0.5.7 (from chromadb==0.3.26)\n",
            "  Downloading clickhouse_connect-0.6.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (966 kB)\n",
            "Requirement already satisfied: duckdb>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.26) (0.8.1)\n",
            "Requirement already satisfied: fastapi>=0.85.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.26) (0.100.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.26) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.26) (1.22.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb==0.3.26)\n",
            "  Downloading posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.26) (4.7.1)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb==0.3.26)\n",
            "  Downloading pulsar_client-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb==0.3.26)\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "Collecting tokenizers>=0.13.2 (from chromadb==0.3.26)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.26) (4.65.0)\n",
            "Collecting overrides>=7.3.1 (from chromadb==0.3.26)\n",
            "  Downloading overrides-7.3.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.26) (2023.5.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.26) (4.6.4)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.26) (1.26.16)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.26) (2022.7.1)\n",
            "Collecting zstandard (from clickhouse-connect>=0.5.7->chromadb==0.3.26)\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "Collecting lz4 (from clickhouse-connect>=0.5.7->chromadb==0.3.26)\n",
            "  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.85.1->chromadb==0.3.26) (0.27.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.3.26)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.3.26) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.3.26) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.3.26) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.3.26) (1.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb==0.3.26) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.3.26) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.3.26)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==0.3.26)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.3.26) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.3.26) (3.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.26) (8.1.6)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.26) (0.14.0)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb==0.3.26)\n",
            "  Downloading httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.3.26)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.26) (6.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb==0.3.26)\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.3.26)\n",
            "  Downloading watchfiles-0.19.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.26) (11.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb==0.3.26) (3.7.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.3.26)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.3.26) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb==0.3.26) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb==0.3.26) (1.1.2)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp310-cp310-linux_x86_64.whl size=2201885 sha256=eeceffe6987dc45c63a3f0595adc8072808bc6877e1a321e87f93f5b59da0c7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/ae/ec/235a682e0041fbaeee389843670581ec6c66872db856dfa9a4\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: tokenizers, monotonic, zstandard, uvloop, requests, python-dotenv, pulsar-client, overrides, lz4, humanfriendly, httptools, hnswlib, backoff, watchfiles, posthog, coloredlogs, clickhouse-connect, onnxruntime, chromadb\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 chromadb-0.3.26 clickhouse-connect-0.6.8 coloredlogs-15.0.1 hnswlib-0.7.0 httptools-0.6.0 humanfriendly-10.0 lz4-4.3.2 monotonic-1.6 onnxruntime-1.15.1 overrides-7.3.1 posthog-3.0.1 pulsar-client-3.2.0 python-dotenv-1.0.0 requests-2.31.0 tokenizers-0.13.3 uvloop-0.17.0 watchfiles-0.19.0 zstandard-0.21.0\n",
            "Collecting sentence-transformers==2.2.2\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers==2.2.2)\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers==2.2.2)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.16.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers==2.2.2) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers==2.2.2) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.13.3)\n",
            "Collecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.2.2) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers==2.2.2) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.5.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=934c905369f4a1e1463a6c2fac064da70a731ce3fedcffe53dba613306709f51\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, safetensors, transformers, sentence-transformers\n",
            "Successfully installed safetensors-0.3.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 transformers-4.31.0\n",
            "Collecting auto-gptq==0.2.2\n",
            "  Downloading auto_gptq-0.2.2.tar.gz (52 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate>=0.19.0 (from auto-gptq==0.2.2)\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "Collecting datasets (from auto-gptq==0.2.2)\n",
            "  Downloading datasets-2.14.0-py3-none-any.whl (492 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from auto-gptq==0.2.2) (1.22.4)\n",
            "Collecting rouge (from auto-gptq==0.2.2)\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq==0.2.2) (2.0.1+cu118)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from auto-gptq==0.2.2) (0.3.1)\n",
            "Requirement already satisfied: transformers>=4.26.1 in /usr/local/lib/python3.10/dist-packages (from auto-gptq==0.2.2) (4.31.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->auto-gptq==0.2.2) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->auto-gptq==0.2.2) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->auto-gptq==0.2.2) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq==0.2.2) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq==0.2.2) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq==0.2.2) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq==0.2.2) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq==0.2.2) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq==0.2.2) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->auto-gptq==0.2.2) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->auto-gptq==0.2.2) (16.0.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->auto-gptq==0.2.2) (0.16.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->auto-gptq==0.2.2) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->auto-gptq==0.2.2) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->auto-gptq==0.2.2) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->auto-gptq==0.2.2) (4.65.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq==0.2.2) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->auto-gptq==0.2.2)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq==0.2.2) (1.5.3)\n",
            "Collecting xxhash (from datasets->auto-gptq==0.2.2)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "Collecting multiprocess (from datasets->auto-gptq==0.2.2)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq==0.2.2) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq==0.2.2) (3.8.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq==0.2.2) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq==0.2.2) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq==0.2.2) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq==0.2.2) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq==0.2.2) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq==0.2.2) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq==0.2.2) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq==0.2.2) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->auto-gptq==0.2.2) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->auto-gptq==0.2.2) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->auto-gptq==0.2.2) (2023.5.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->auto-gptq==0.2.2) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq==0.2.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq==0.2.2) (2022.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->auto-gptq==0.2.2) (1.3.0)\n",
            "Building wheels for collected packages: auto-gptq\n",
            "  Building wheel for auto-gptq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for auto-gptq: filename=auto_gptq-0.2.2-cp310-cp310-linux_x86_64.whl size=2850542 sha256=33378a7c1c40bb653e9714f07da650c60e5dce238a89ad642322ac8a7fe70cc2\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/f6/50/bb6ab784e7824cbf190a1a8205d91e6543287718fb21d5b033\n",
            "Successfully built auto-gptq\n",
            "Installing collected packages: xxhash, rouge, dill, multiprocess, datasets, accelerate, auto-gptq\n",
            "Successfully installed accelerate-0.21.0 auto-gptq-0.2.2 datasets-2.14.0 dill-0.3.7 multiprocess-0.70.15 rouge-1.0.1 xxhash-3.2.0\n",
            "Collecting einops==0.6.1\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.6.1\n",
            "Collecting unstructured==0.8.0\n",
            "  Downloading unstructured-0.8.0-py3-none-any.whl (1.4 MB)\n",
            "Collecting argilla (from unstructured==0.8.0)\n",
            "  Downloading argilla-1.13.2-py3-none-any.whl (2.7 MB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured==0.8.0) (4.0.0)\n",
            "Collecting filetype (from unstructured==0.8.0)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured==0.8.0) (4.9.3)\n",
            "Collecting msg-parser (from unstructured==0.8.0)\n",
            "  Downloading msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured==0.8.0) (3.8.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from unstructured==0.8.0) (3.0.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from unstructured==0.8.0) (1.5.3)\n",
            "Collecting pdf2image (from unstructured==0.8.0)\n",
            "  Downloading pdf2image-1.16.3-py3-none-any.whl (11 kB)\n",
            "Collecting pdfminer.six (from unstructured==0.8.0)\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unstructured==0.8.0) (8.4.0)\n",
            "Collecting pypandoc (from unstructured==0.8.0)\n",
            "  Downloading pypandoc-1.11-py3-none-any.whl (20 kB)\n",
            "Collecting python-docx (from unstructured==0.8.0)\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-pptx (from unstructured==0.8.0)\n",
            "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-magic (from unstructured==0.8.0)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured==0.8.0) (3.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured==0.8.0) (2.31.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured==0.8.0) (0.9.0)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from unstructured==0.8.0) (2.0.1)\n",
            "Collecting httpx<0.24,>=0.15 (from argilla->unstructured==0.8.0)\n",
            "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
            "Collecting deprecated~=1.2.0 (from argilla->unstructured==0.8.0)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured==0.8.0) (23.1)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.10.7 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured==0.8.0) (1.10.11)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.13 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured==0.8.0) (1.14.1)\n",
            "Requirement already satisfied: numpy<1.24.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured==0.8.0) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured==0.8.0) (4.65.0)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured==0.8.0) (2.2.1)\n",
            "Requirement already satisfied: monotonic in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured==0.8.0) (1.6)\n",
            "Requirement already satisfied: rich!=13.1.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured==0.8.0) (13.4.2)\n",
            "Collecting typer<0.8.0,>=0.6.0 (from argilla->unstructured==0.8.0)\n",
            "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured==0.8.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured==0.8.0) (2022.7.1)\n",
            "Collecting olefile>=0.46 (from msg-parser->unstructured==0.8.0)\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.8.0) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.8.0) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.8.0) (2022.10.31)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->unstructured==0.8.0) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured==0.8.0) (2.0.12)\n",
            "Collecting cryptography>=36.0.0 (from pdfminer.six->unstructured==0.8.0)\n",
            "  Downloading cryptography-41.0.2-cp37-abi3-manylinux_2_28_x86_64.whl (4.3 MB)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx->unstructured==0.8.0)\n",
            "  Downloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured==0.8.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured==0.8.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured==0.8.0) (2023.5.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured==0.8.0) (1.15.1)\n",
            "Collecting httpcore<0.17.0,>=0.15.0 (from httpx<0.24,>=0.15->argilla->unstructured==0.8.0)\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "Collecting rfc3986[idna2008]<2,>=1.3 (from httpx<0.24,>=0.15->argilla->unstructured==0.8.0)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured==0.8.0) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0,>=1.10.7->argilla->unstructured==0.8.0) (4.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->unstructured==0.8.0) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich!=13.1.0->argilla->unstructured==0.8.0) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich!=13.1.0->argilla->unstructured==0.8.0) (2.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured==0.8.0) (2.21)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured==0.8.0) (0.14.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured==0.8.0) (3.7.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich!=13.1.0->argilla->unstructured==0.8.0) (0.1.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured==0.8.0) (1.1.2)\n",
            "Building wheels for collected packages: python-docx, python-pptx, olefile\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184491 sha256=1656f38fffbd6bbb91d2b6773d58a618d1bafee7b776a2fc1dfaaab376631532\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470935 sha256=278c71625e86331aed7565ecefa9e0bc5f2bb066181b0f5d23c512e49ea67ac7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/dd/74/01b3ec7256a0800b99384e9a0f7620e358afc3a51a59bf9b49\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35417 sha256=3f692b9bfd8c170e7f79345e8d204bc6e0edc1b651d472c0597b6dd3d09cb103\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/39/c0/9eb1f7a42b4b38f6f333b6314d4ed11c46f12a0f7b78194f0d\n",
            "Successfully built python-docx python-pptx olefile\n",
            "Installing collected packages: rfc3986, filetype, XlsxWriter, typer, python-magic, python-docx, pypandoc, pdf2image, olefile, deprecated, python-pptx, msg-parser, httpcore, cryptography, pdfminer.six, httpx, argilla, unstructured\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.0\n",
            "    Uninstalling typer-0.9.0:\n",
            "      Successfully uninstalled typer-0.9.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 0.17.3\n",
            "    Uninstalling httpcore-0.17.3:\n",
            "      Successfully uninstalled httpcore-0.17.3\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 3.4.8\n",
            "    Uninstalling cryptography-3.4.8:\n",
            "      Successfully uninstalled cryptography-3.4.8\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.24.1\n",
            "    Uninstalling httpx-0.24.1:\n",
            "      Successfully uninstalled httpx-0.24.1\n",
            "Successfully installed XlsxWriter-3.1.2 argilla-1.13.2 cryptography-41.0.2 deprecated-1.2.14 filetype-1.2.0 httpcore-0.16.3 httpx-0.23.3 msg-parser-1.2.0 olefile-0.46 pdf2image-1.16.3 pdfminer.six-20221105 pypandoc-1.11 python-docx-0.8.11 python-magic-0.4.27 python-pptx-0.6.21 rfc3986-1.5.0 typer-0.7.0 unstructured-0.8.0\n",
            "Collecting transformers==4.30.2\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (2023.5.7)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.31.0\n",
            "    Uninstalling transformers-4.31.0:\n",
            "      Successfully uninstalled transformers-4.31.0\n",
            "Successfully installed transformers-4.30.2\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from auto_gptq import AutoGPTQForCausalLM\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.memory import ConversationSummaryMemory, ChatMessageHistory\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from transformers import AutoTokenizer, GenerationConfig, TextStreamer, pipeline\n"
      ],
      "metadata": {
        "id": "o_FvUQE70VQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dgfc9FNVzcPz"
      },
      "outputs": [],
      "source": [
        "# Define directory for storing questions and function for writing QA to file\n",
        "questions_dir=Path(\"Microsoft_QA\")\n",
        "questions_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "def write_file(question, answer, file_path):\n",
        "    text = f\"\"\"\n",
        "    Q: {question}\n",
        "    A: {answer}\n",
        "    \"\"\".strip()\n",
        "    with Path(questions_dir / file_path).open(\"w\") as text_file:\n",
        "      text_file.write(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Call write_file function with specified question, answer, and file path\n",
        "write_file(\n",
        "    question=\"What is Microsoft Q&A?\",\n",
        "    answer=\"\"\"Microsoft Q&A is a Microsoft site where you can get fast access to\n",
        "     questions about Microsoft technologies with Q&A, a global, community-driven\n",
        "      platform for timely, high-quality technical answers.\"\"\".strip(),\n",
        "    file_path=\"question_1.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"I saw you launched a new Q&A site on January 10, 2023. Why?\",\n",
        "    answer=\"\"\"We know how important it's for you to have access to fast,\n",
        "     accurate answers to questions about Microsoft technologies. The new site has improved\n",
        "     workflows and the user interface is optimized for readability and efficiency. We also have a\n",
        "    more integrated experience with the Microsoft Learn ecosystem. Check out all the changes in our release notes.\"\"\".strip(),\n",
        "    file_path=\"question_2.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"What are the major benefits of Microsoft Q&A versus Stack Overflow?\",\n",
        "    answer=\"\"\"We love Stack Overflow. We will continue supporting our customers who ask questions there. We also surface answers from Stack Overflow on Microsoft Q&A.\n",
        "\n",
        "Stack Overflow has specific criteria about what questions are appropriate for the community whereas Microsoft Q&A has an open policy regarding this, where all questions about Microsoft technologies are welcomed. More importantly, via Microsoft Q&A we can create unique experiences that allow us to provide the highest level of support for our customers. It's hard to get a full picture of the customer who is asking a question on Stack Overflow. However, on Microsoft Q&A we can connect the asker to their actual product usage and support contract. This enables new opportunities to offer the highest quality support.\"\"\".strip(),\n",
        "    file_path=\"question_3.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"What is the difference between Microsoft Q&A and Microsoft Tech Community?\",\n",
        "    answer=\"\"\"Microsoft Q&A is first party experience for technical answers on Microsoft products. Developers and IT pros can solve problems with the help of community experts and Microsoft engineering. The experience includes a rich knowledge base which ingests content from MSDN Forums and Stack Overflow to help customers get the answers they need quickly.\n",
        "\n",
        "Microsoft Tech Community provides a connection between customers, Microsoft and community experts to share best practice and ideas, receive supportive encouragement and learn through discussions and blogs across Azure and Microsoft 365 products and programs.\"\"\".strip(),\n",
        "    file_path=\"question_4.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"I heard Microsoft Q&A only supports English. Is there any plan to support non-English?\",\n",
        "    answer=\"\"\"Yes, one of the benefits of the new site we launched on January 10 is that we can start supporting other languages. Stay tuned for more news about that.\"\"\".strip(),\n",
        "    file_path=\"question_5.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"How do I report a new feature or a bug for Microsoft Q&A?\",\n",
        "    answer=\"\"\"Until we move to a unified product feedback, you can continue providing feedback about Q&A by using the In the meantime, you can provide us feedback by using the Microsoft Q&A tag.\"\"\".strip(),\n",
        "    file_path=\"question_6.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"Where can I report offensive content?\",\n",
        "    answer=\"\"\"Select the Report option next to the content you would like to report. From the drop-down box, select the reason for the offensive post. See more details in the report content article.\n",
        "\n",
        "A moderator will review this report and act on it.\"\"\".strip(),\n",
        "    file_path=\"question_7.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"Is Microsoft Q&A mobile-friendly?\",\n",
        "    answer=\"\"\"The site is accessible and usable on mobile devices.\"\"\".strip(),\n",
        "    file_path=\"question_8.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"How do I create an account?\",\n",
        "    answer=\"\"\"If you have an account through Microsoft Learn, you can use the same account information here. If not, in the top right corner of the Q&A site you will see an option to sign in, which takes you to the process to create a new account. For more information, visit Managing your Microsoft Learn profile.\"\"\".strip(),\n",
        "    file_path=\"question_9.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"How do I sign in?\",\n",
        "    answer=\"\"\"In the Microsoft Q&A header, select Sign in. You can use the same user profile that you use on Microsoft Learn.\"\"\".strip(),\n",
        "    file_path=\"question_10.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"Can other users see my email address?\",\n",
        "    answer=\"\"\"No. Take a look at another user's profile and you'll notice that an email address is not listed. The same goes for users who look at your user profile.\"\"\".strip(),\n",
        "    file_path=\"question_11.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"Why do I have to navigate to different pages to find the content that I am looking for instead of having infinite scrolling?\",\n",
        "    answer=\"\"\"Infinite scrolling is not meant for our type of content. It has some issues such us: Difficulty re-finding content; Illusion of completeness; Inability to access the end of the page; Accessibility problems (users have to tab forever); Increased page load; Poor SEO performance.\"\"\".strip(),\n",
        "    file_path=\"question_12.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"Why is there so much empty space on the right and left columns on the question threads? Can you expand the text to cover the full width of the page?\",\n",
        "    answer=\"\"\"The design is to keep consistency across the Microsoft Learn site. It's design to improve readability to all users. Here are some resources that explains this in detail: [https://m.mediawiki.org/wiki/Reading/Web/Desktop_Improvements/Features/Limiting_content_width/]( Reading/Web/Desktop Improvements/Features/Limiting content width), [https://www.w3.org/WAI/WCAG21/Understanding/visual-presentation#dfn-blocks-of-text](Visual presentation of blocks of text), (https://baymard.com/blog/line-length-readability)[Line length readability].\"\"\".strip(),\n",
        "    file_path=\"question_13.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"How do I ask a question?\",\n",
        "    answer=\"\"\"In the Microsoft Q&A header, select the Ask a question button. As you type in your question, we will show you similar questions that have already been asked on Q&A and other sources. Make sure to check these because someone may have already answered your question.\n",
        "\n",
        "You can find more details on best practices when asking questions in the How to write a quality question article.\"\"\".strip(),\n",
        "    file_path=\"question_14.txt\",\n",
        ")\n",
        "\n",
        "write_file(\n",
        "    question=\"How do I know if a user is knowledgeable?\",\n",
        "    answer=\"\"\"If a user participates in and contributes positively to the community frequently, they will win points. The more reputation points a user has, the more likely they're to have expertise on the topic they're posting.\n",
        "\n",
        "We also show Microsoft affiliations in the user's cards: Microsoft Employee, Microsoft Agency Temporary, Microsoft Vendor, Microsoft Intern, and Microsoft Most Valuable Professionals (MVPs), so you know if the answer comes from a Microsoft-trusted source.\"\"\".strip(),\n",
        "    file_path=\"question_16.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"How can I sort all the questions?\",\n",
        "    answer=\"\"\"At the top right of the questions page, you can see a Sort by drop-down menu. Select the option you would like to sort the content by. You can also filter out the content based on different criteria. Check our filter and sort article for details.\"\"\".strip(),\n",
        "    file_path=\"question_17.txt\",\n",
        ")\n",
        "\n",
        "write_file(\n",
        "    question=\"Who can answer a question?\",\n",
        "    answer=\"\"\"Anyone signed in user can help others by answering a question on Microsoft Q&A. If you know the answer to a question, support the online community by answering it!\"\"\".strip(),\n",
        "    file_path=\"question_19.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"Can I vote my own content?\",\n",
        "    answer=\"\"\"You can't vote your own questions, comments, or answers.\"\"\".strip(),\n",
        "    file_path=\"question_20.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"Can I vote on a question, answer, or comment more than once?\",\n",
        "    answer=\"\"\"No, you can only vote once. You can change or cancel your vote if you change your mind.\"\"\".strip(),\n",
        "    file_path=\"question_21.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"What are tags?\",\n",
        "    answer=\"\"\"Tags are topics related to your thread that help group and organize all the content on Microsoft Q&A. You can add tags to any kind of post by searching from a wide range of topics in the question that you're creating.\"\"\".strip(),\n",
        "    file_path=\"question_22.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"Do I have to add tags to a new question?\",\n",
        "    answer=\"\"\"Yes, a minimum of 1 tag is required for each question. This helps the experts on that tag to monitor and answer your questions. The more tags you add the more information the community receives, making it easier to find similar questions and answer them.\"\"\".strip(),\n",
        "    file_path=\"question_23.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"How do I follow a tag?\",\n",
        "    answer=\"\"\"Following a tag allows you to get alerts on the tag related to a particular service. To follow a tag, select Tags on the header, and hover the tag you want to follow. Select the Follow button. You can also follow tags from other pages by hovering on the tag and selecting on the Follow button.\n",
        "\n",
        "If you want to receive notifications when a question is posted on the tags you follow, select your Avatar, and then Settings. Make sure you have an email for notifications. Then, on Q&A preferences section, select Receive email when a question is posted on a tag you follow and Follow questions with tags you're following and select Save. You can find more details in the Q&A preferences article.\"\"\".strip(),\n",
        "    file_path=\"question_24.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"Can I create a new tag?\",\n",
        "    answer=\"\"\"Users can't create new tags at this moment.\"\"\".strip(),\n",
        "    file_path=\"question_25.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"What are reputation points?\",\n",
        "    answer=\"\"\"Reputation points are earned by participating in and contributing positively to the community. For more information on reputation points, see the reputation points help article.\"\"\".strip(),\n",
        "    file_path=\"question_26.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"How can I manage my settings?\",\n",
        "    answer=\"\"\"In the Microsoft Q&A header, select your avatar in the top right, then select Settings. This will take you to your profile page where you can provide a notification email address as well as your Microsoft Learn and Q&A settings. You can find more details on the Q&A preferences article.\"\"\".strip(),\n",
        "    file_path=\"question_27.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"How do I update my profile?\",\n",
        "    answer=\"\"\"In the Microsoft Q&A header, select your avatar in the top right and then select Profile. Here you will see options to update the different parts of your profile.\"\"\".strip(),\n",
        "    file_path=\"question_28.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"How can I subscribe/unsubscribe to get email notifications on different kinds of threads?\",\n",
        "    answer=\"\"\"In the Microsoft Q&A header, select your avatar on the top right, and then select Settings. Under Q&A preferences you can choose what kinds of threads on Microsoft Q&A you get notified about and how often. You can find more details on the Q&A preferences article.\"\"\".strip(),\n",
        "    file_path=\"question_29.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"How can I see all the questions I save in a collection?\",\n",
        "    answer=\"\"\"Select your avatar in the top right of the Microsoft Q&A header and then select Profile. Select Collections on the left section.\"\"\".strip(),\n",
        "    file_path=\"question_30.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"How can I view the questions and answers I've interacted with?\",\n",
        "    answer=\"\"\"Select your avatar in the top right of the Microsoft Q&A header and then select Profile. Under Activity you will see up to 30 interactions over the past 30 days..\n",
        "\n",
        "\"\"\".strip(),\n",
        "    file_path=\"question_31.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"What can moderators do?\",\n",
        "    answer=\"\"\"Moderators are a part of the Microsoft Q&A community to maintain high quality content. Moderators can delete/undelete content, ban users, redirect threads, close threads, and edit content to keep threads relevant and appropriate.\"\"\".strip(),\n",
        "    file_path=\"question_32.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"If a moderator's message gets flagged, can they cancel that report?\",\n",
        "    answer=\"\"\"They can't, only another moderator will be able to.\"\"\".strip(),\n",
        "    file_path=\"question_33.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"Can moderators mark answers as Accepted Answers?\",\n",
        "    answer=\"\"\"No, only the question author have those permissions.\"\"\".strip(),\n",
        "    file_path=\"question_34.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"What happens to the ongoing conversations in MSDN and TechNet forums that are closed to all new and existing threads?\",\n",
        "    answer=\"\"\"You will still be able to view the forums, you just won't be able to ask new questions or create new responses. You can also see the questions surfaced in Microsoft Q&A whenever you ask a question or search on the site.\"\"\".strip(),\n",
        "    file_path=\"question_35.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"Will the content from MSDN and TechNet forums be migrated into Microsoft Q&A?\",\n",
        "    answer=\"\"\"No. When a user searches for something that doesn't appear when they're browsing on Microsoft Q&A, we use machine learning to display read-only questions and answers from MSDN and TechNet forums.\"\"\".strip(),\n",
        "    file_path=\"question_36.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"Will I lose my MSDN and TechNet reputations?\",\n",
        "    answer=\"\"\"Currently you can't carry over your MSDN and TechNet reputation. We are working to give you the opportunity to link Microsoft Q&A and MSDN and TechNet forums. When this is an option, your current badges and points from MSDN and TechNet forums will be displayed as part of your Microsoft Q&A profile.\"\"\".strip(),\n",
        "    file_path=\"question_37.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"Can I keep the same user profile I have on MSDN and TechNet forums?\",\n",
        "    answer=\"\"\"To use Microsoft Q&A you'll need to make a new profile (though you can keep your MSDN or TechNet identity). The new user profile you will create for Microsoft Q&A will be linked to Microsoft Learn. So if you already have an account for those sites, you can use the same one on Microsoft Q&A.\"\"\".strip(),\n",
        "    file_path=\"question_38.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"I'm a moderator in MSDN and TechNet forums, will I be a moderator on Microsoft Q&A?\",\n",
        "    answer=\"\"\"All moderators in MSDN and TechNet forums can continue being moderators. Follow the process described on the Microsoft Q&A moderators article.\"\"\".strip(),\n",
        "    file_path=\"question_39.txt\",\n",
        ")\n",
        "write_file(\n",
        "    question=\"Where does Microsoft Q&A store customer data?\",\n",
        "    answer=\"\"\"Microsoft Q&A doesn't move or store customer data out of the region it's deployed in.\"\"\".strip(),\n",
        "    file_path=\"question_40.txt\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "kWBWOsG20oX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model and tokenizer names\n",
        "model_name = \"TheBloke/Nous-Hermes-13B-GPTQ\"\n",
        "model_basename = \"nous-hermes-13b-GPTQ-4bit-128g.no-act.order\"\n",
        "# Load tokenizer from model nam\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast= True)\n",
        "# Load quantized model from model name and basename\n",
        "model = AutoGPTQForCausalLM.from_quantized(\n",
        "    model_name,\n",
        "    model_basename= model_basename,\n",
        "    use_safetensors=True,\n",
        "    Trust_remote_code=True,\n",
        ")\n",
        "\n",
        "generation_config = GenerationConfig.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243,
          "referenced_widgets": [
            "ec6c5124bfa04f6eac38bae372486a53",
            "3c15e81bc9ce487fac697e548ef91fc2",
            "412de8f62654475c965a98cd21bb4232",
            "e6da5a49d8f94740a97b14984be88b96",
            "4b7e5479b3a648d682511d08cd8a3c0a",
            "a5a5324cfc204e4687c13c088ddc445c",
            "22601a9f3663498d88e2d4837e3a7e39",
            "2fb7256278f64e79b3f0699c4e6e616d",
            "416755961d8a4a79bd691cf60ae85c11",
            "d95ff992a038470dae5ea25e75a444bb",
            "5dae32026672413e85ad0faf45a58660",
            "6001697917dc48b99dc57ab518c41658",
            "a4288aacbe864119abd4d8ff643f4335",
            "359d1d433eac4a8d9209d3e662664acd",
            "14da015ab8e449128d8e13647c25c010",
            "dc58938c310e4a7081ed9056ed33cfac",
            "b1d82b8fe87547bf976721f641cc0709",
            "7b48af65e2824d398ee696d2bbe05551",
            "9f230860c77442d7ad9b589ce5f79281"
          ]
        },
        "id": "awAoH58RD3GC",
        "outputId": "26bb22d7-bc01-4e80-b9e7-0ca6f9149f90"
      },
      "execution_count": 7,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec6c5124bfa04f6eac38bae372486a53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c15e81bc9ce487fac697e548ef91fc2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "412de8f62654475c965a98cd21bb4232",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6da5a49d8f94740a97b14984be88b96",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)in/added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b7e5479b3a648d682511d08cd8a3c0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5a5324cfc204e4687c13c088ddc445c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/606 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22601a9f3663498d88e2d4837e3a7e39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)quantize_config.json:   0%|          | 0.00/135 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fb7256278f64e79b3f0699c4e6e616d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)ct.order.safetensors:   0%|          | 0.00/7.45G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.utils.modeling:The safetensors archive passed at /root/.cache/huggingface/hub/models--TheBloke--Nous-Hermes-13B-GPTQ/snapshots/d4618f374d36ff4cecac6ca13827f8388ebf9cc2/nous-hermes-13b-GPTQ-4bit-128g.no-act.order.safetensors does not contain metadata. Make sure to save your model with the `save_pretrained` method. Defaulting to 'pt' metadata.\n",
            "WARNING:auto_gptq.nn_modules.fused_llama_mlp:skip module injection for FusedLlamaMLPForQuantizedModel not support integrate without triton yet.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/141 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "416755961d8a4a79bd691cf60ae85c11"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#query and prompt to test llm\n",
        "question = (\" what is the most heared song in the history of music\")\n",
        "prompt = f\"\"\"\n",
        "### Instructions: {question}\n",
        "### Response:\n",
        "\"\"\".strip()"
      ],
      "metadata": {
        "id": "AgUlvOUhEsP7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load generation configuration from model name\n",
        "generation_config = GenerationConfig.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "Y9VclsomC0QY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TextStreamer object with specified tokenizer and settings\n",
        "streamer = TextStreamer(\n",
        "    tokenizer, skip_prompt = True, skip_special_tokens=True, use_multiprocessing = False\n",
        ")"
      ],
      "metadata": {
        "id": "4C1JDXaPGjMb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create text generation pipeline with specified model, tokenizer, and generation parameters\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer= tokenizer,\n",
        "    max_length=2048,\n",
        "    temperature=0,\n",
        "    top_p=0.95,\n",
        "    repetition_penalty=1.15,\n",
        "    generation_config=generation_config,\n",
        "    streamer=streamer,\n",
        "    batch_size=1,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "v_ijQSWxGzco",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cefb32f-6da9-4ca9-e364-2c9054110834"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n",
            "The model 'LlamaGPTQForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create HuggingFacePipeline object with specified pipeline\n",
        "llm=HuggingFacePipeline(pipeline=pipe)\n"
      ],
      "metadata": {
        "id": "YVvSJ5F-HUS9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm(prompt)\n",
        "response\n",
        "\n"
      ],
      "metadata": {
        "id": "UVogKw5LHaIx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "b6a36165-bf04-4dad-b625-29262a235cf6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It's difficult to determine the \"most heard\" or \"best-selling\" song in the history of music, as it varies over time and depends on factors such as genre, era, and region. However, some of the best-selling songs worldwide include \"Bohemian Rhapsody\" by Queen, \"Like a Virgin\" by Madonna, \"Thriller\" by Michael Jackson, and \"Smells Like Teen Spirit\" by Nirvana. These songs have sold millions of copies and are considered classics that continue to resonate with audiences today.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'It\\'s difficult to determine the \"most heard\" or \"best-selling\" song in the history of music, as it varies over time and depends on factors such as genre, era, and region. However, some of the best-selling songs worldwide include \"Bohemian Rhapsody\" by Queen, \"Like a Virgin\" by Madonna, \"Thriller\" by Michael Jackson, and \"Smells Like Teen Spirit\" by Nirvana. These songs have sold millions of copies and are considered classics that continue to resonate with audiences today.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Embed** **Documents**"
      ],
      "metadata": {
        "id": "V9LBSd_6JMSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create HuggingFaceEmbeddings object with specified model name\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name= 'embaas/sentence-transformers-multilingual-e5-base'\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "MkX2NN0_JSNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load documents from directory using DirectoryLoader class\n",
        "loader = DirectoryLoader(\"./Microsoft_QA/\", glob=\"**/*txt\")\n",
        "documents = loader.load()\n",
        "len(documents)"
      ],
      "metadata": {
        "id": "w8120FNCJokh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split documents into chunks using CharacterTextSplitter class\n",
        "text_splitter = CharacterTextSplitter(chunk_size=512, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n"
      ],
      "metadata": {
        "id": "gZ42KF_9KYm0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Chroma database from documents and embeddings\n",
        "db = Chroma.from_documents(texts, embeddings)"
      ],
      "metadata": {
        "id": "l-V0IeR-KohD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prompt template for generating responses\n",
        "template = \"\"\"\n",
        "### Instruction: You're a microsoft QA platform support agent who is talking to user giving them information about the platform. Use only the chat history and the following information\n",
        "{context}\n",
        "to answer in a helpful manner to the question. if you dont know the answer - say I am not able to solve this problem myself. I will connect you to one of our human chat operators who will surely be able to help you!.\n",
        "Keep your replies short, compassionate and informative.\n",
        "{chat_history}\n",
        "\n",
        "### Input: {question}\n",
        "### Responses:\n",
        "\"\"\".strip()"
      ],
      "metadata": {
        "id": "Z-kAgZ8RUEC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(input_variables=[\"context\",\"question\",\"chat_history\"], template=template)\n"
      ],
      "metadata": {
        "id": "3Nv94wKsU207"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ConversationBufferMemory object to store chat history\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
      ],
      "metadata": {
        "id": "zYQu1_bKKLNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ConversationalRetrievalChain object from LLM, database retriever, memory, and prompt\n",
        "qa = ConversationalRetrievalChain.from_llm(\n",
        "     llm,\n",
        "     db.as_retriever(),\n",
        "     memory=memory,\n",
        "     combine_docs_chain_kwargs= {\"prompt\": prompt},\n",
        "     #return_source_documents= True,\n",
        "     )"
      ],
      "metadata": {
        "id": "AsQH4Xs-KPej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing our chain\n",
        "query = \"tell me more about microsoft QA\"\n",
        "result = qa({\"question\": query})"
      ],
      "metadata": {
        "id": "Zk8MDdHbKejd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a25681d-962e-4e8b-9276-9742d9eb59b0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Microsoft Q&A is a platform designed specifically for getting quick and accurate answers to any questions related to Microsoft technologies. It's a community-driven experience where developers and IT professionals can collaborate with each other as well as with Microsoft engineers to find solutions to common issues or complex problems. With its advanced algorithms and machine learning capabilities, Microsoft Q&A provides users with relevant and up-to-date information from various sources, including MSDN Forums and Stack Overflow. Additionally, Microsoft Q&A offers a personalized experience by taking into account the user's activity and preferences within the platform. Overall, Microsoft Q&A is a comprehensive and efficient tool for anyone looking to improve their understanding and use of Microsoft technologies.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import time\n",
        "# Create Gradio user interface with Chatbot and Textbox components and ClearButton for clearing input/output\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "# Define function for handling user input and updating chat history\n",
        "    def user(user_message, history):\n",
        "        return gr.update(value=\"\", interactive=False), history + [[user_message, None]]\n",
        "# Define function for generating bot response using ConversationalRetrievalChain object and updating chat history\n",
        "    def bot(history):\n",
        "        response = qa(history[-1][0])\n",
        "        response = response['answer']\n",
        "\n",
        "        history[-1][1] = \"\"\n",
        "        for character in response:\n",
        "            history[-1][1] += character\n",
        "            time.sleep(0.05)\n",
        "            yield history\n",
        " # Submit user input to user function and update chat history, then generate bot response using bot function and update chat history\n",
        "    response = msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "        bot, chatbot, chatbot\n",
        "    )\n",
        "    # Update Gradio interface to be interactive after bot response is generated\n",
        "    response.then(lambda: gr.update(interactive=True), None, [msg], queue=False)\n",
        "    # Launch Gradio interface with sharing enabled\n",
        "    demo.queue()\n",
        "    demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "Oe606ibjw5lV",
        "outputId": "d58c1a9c-c879-481f-f3ab-193ff03be6e2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://b87ed8328308be4f51.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://b87ed8328308be4f51.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    }
  ]
}